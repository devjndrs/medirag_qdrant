# ü©∫ MediRAG: Advanced Medical RAG System

![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python&logoColor=white)
![Qdrant](https://img.shields.io/badge/Qdrant-Vector_DB-red?style=for-the-badge&logo=qdrant&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-Framework-green?style=for-the-badge&logo=langchain&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Containerization-2496ED?style=for-the-badge&logo=docker&logoColor=white)

## üìñ Introducci√≥n

**MediRAG** es un sistema de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)** de grado industrial dise√±ado para el dominio m√©dico. A diferencia de los tutoriales b√°sicos de RAG, este proyecto se centra en la **ingenier√≠a de datos robusta**, la arquitectura modular y los patrones de dise√±o avanzados necesarios para desplegar sistemas de IA generativa en producci√≥n.

Este repositorio no es solo un chatbot; es una implementaci√≥n de referencia de c√≥mo construir pipelines de datos resilientes, escalables y mantenibles para aplicaciones de LLM.

---

## üéØ Importancia para Equipos de ML e IA

En el ecosistema actual de IA Generativa, el **80% del √©xito de un sistema RAG reside en la calidad de su ingenier√≠a de datos**, no solo en el modelo de lenguaje elegido.

Para un equipo de ML/IA, adoptar un enfoque de ingenier√≠a como el de MediRAG ofrece ventajas cr√≠ticas:

### üöÄ Ventajas Competitivas
1.  **Reproducibilidad y Determinismo**: El uso de entornos gestionados (`uv`, Docker) y pipelines orquestados elimina el problema de "funciona en mi m√°quina".
2.  **Calidad de Datos Superior**: La implementaci√≥n de estrategias de *Parent-Child Splitting* y *Reranking* asegura que el LLM reciba contexto preciso, reduciendo dr√°sticamente las alucinaciones.
3.  **Mantenibilidad a Largo Plazo**: La arquitectura basada en principios **SOLID** y **Dependency Injection** permite cambiar componentes (ej. cambiar Qdrant por Pinecone, o Gemini por GPT-4) sin reescribir el n√∫cleo del sistema.
4.  **Observabilidad y Testing**: Tratar los datos como c√≥digo mediante tests de integridad y pipelines de validaci√≥n E2E permite detectar degradaci√≥n en la calidad de las respuestas antes de llegar a producci√≥n.

---

## üèóÔ∏è Arquitectura y Fases del Proyecto

### üîπ Fase 1: Infraestructura y Pipeline de Ingesti√≥n (Data Engineering)
Establecimiento de una base s√≥lida enfocada en la reproducibilidad y escalabilidad.

*   **Gesti√≥n de Dependencias**: Uso de `uv` para entornos virtuales deterministas.
*   **Vector Database**: Despliegue de **Qdrant** v√≠a Docker Compose con persistencia de datos.
*   **ETL Modular (SOLID)**:
    *   **Abstracci√≥n**: Interfaces `BaseLoader` y `BaseCleaner` para extensibilidad.
    *   **Extracci√≥n**: `PDFLoader` optimizado con `pypdf`.
    *   **Limpieza**: `MedicalTextCleaner` inyectado como dependencia para facilitar tests.

### üîπ Fase 2: Transformaci√≥n y Estrategia de Recuperaci√≥n
Transformaci√≥n de data cruda en estructuras optimizadas para b√∫squeda sem√°ntica.

*   **Parent-Document Pattern**:
    *   *Child Chunks*: Peque√±os, optimizados para b√∫squeda vectorial (similitud coseno).
    *   *Parent Chunks*: Grandes, optimizados para dar contexto completo al LLM.
*   **Vectorizaci√≥n Local**: Uso de `sentence-transformers` para inferencia r√°pida y sin coste.
*   **Ingesti√≥n por Lotes**: Carga masiva en Qdrant para optimizar I/O de red.

### üîπ Fase 3: Orquestaci√≥n Inteligente (Advanced RAG)
Evoluci√≥n hacia un asistente conversacional con razonamiento refinado.

*   **LLM Integration**: Google Gemini 1.5 Flash para s√≠ntesis de respuestas.
*   **Memoria Conversacional**: Sistema de ventana deslizante para mantener contexto del chat.
*   **Query Rewriting**: Reformulaci√≥n de preguntas basada en el historial para mejorar el retrieval.
*   **Two-Stage Retrieval**:
    1.  **Wide Fetch**: B√∫squeda vectorial r√°pida (High Recall).
    2.  **Deep Rerank**: Reordenamiento con **FlashRank** (Cross-Encoder) para m√°xima precisi√≥n sem√°ntica.

### üîπ Fase 4: Validaci√≥n y CI/CD de Datos
Garant√≠a de fiabilidad en entornos productivos.

*   **Pipeline de Pruebas E2E**: Orquestador (`src/run_pipeline.py`) que valida secuencialmente:
    1.  Sanity Checks (Entorno/DB).
    2.  Integridad de Datos (ETL).
    3.  L√≥gica de Transformaci√≥n.
    4.  Calidad de Retrieval y Reranking.
    5.  Generaci√≥n Final.

---

## üõ†Ô∏è Gu√≠a de Instalaci√≥n y Uso

### Prerrequisitos
*   **Docker** y **Docker Compose** instalados.
*   **Python 3.11+**.
*   **uv** (Recomendado) o `pip`.
*   API Key de Google Gemini (en `.env`).

### 1. Configuraci√≥n del Entorno

```bash
# Clonar el repositorio
git clone <repo-url>
cd chatbotMedico

# Crear entorno virtual e instalar dependencias
uv venv
source .venv/bin/activate
uv pip install -r pyproject.toml  # O requirements.txt si se genera
```

### 2. Levantar Infraestructura

```bash
# Iniciar Qdrant
docker-compose up -d
```

### 3. Ejecutar Pipeline Completo (Validaci√≥n E2E)

Para ejecutar todo el flujo, desde la ingesta hasta la prueba del chat, utiliza el orquestador:

```bash
python src/run_pipeline.py
```

Este comando ejecutar√° autom√°ticamente:
*   Verificaci√≥n de conexi√≥n a Qdrant.
*   Descarga del paper m√©dico de muestra.
*   Procesamiento, limpieza y vectorizaci√≥n.
*   Pruebas de b√∫squeda y generaci√≥n de respuesta.

---

## üìÇ Estructura del Proyecto

```text
src/
‚îú‚îÄ‚îÄ core/           # Configuraci√≥n y definiciones de tipos
‚îú‚îÄ‚îÄ ingestion/      # Loaders, Cleaners y Splitters (ETL)
‚îú‚îÄ‚îÄ retrieval/      # L√≥gica de b√∫squeda y Reranking
‚îú‚îÄ‚îÄ generation/     # Integraci√≥n con LLM y cadenas RAG
‚îú‚îÄ‚îÄ vector_store/   # Cliente y gesti√≥n de Qdrant
‚îú‚îÄ‚îÄ testing/        # Tests unitarios y de integraci√≥n
‚îî‚îÄ‚îÄ run_pipeline.py # Orquestador maestro
```

---

> **Nota**: Este proyecto demuestra que un sistema RAG efectivo es mucho m√°s que un script de 50 l√≠neas. Es un sistema de ingenier√≠a de software completo que requiere dise√±o, pruebas y una arquitectura s√≥lida.
